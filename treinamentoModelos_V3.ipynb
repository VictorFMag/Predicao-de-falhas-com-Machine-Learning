{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "czYYtRNBCccm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "eJVFgpWOCuNX"
      },
      "outputs": [],
      "source": [
        "# Preparando os dados\n",
        "original_data = pd.read_excel('Construtoras_sintetico_completo_V2.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz7oaEaMCwF4",
        "outputId": "b39ee78f-fe89-4747-d733-d6ffbe13a8e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21427, 69)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = original_data.copy()\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3675, 69)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simplified_data = pd.DataFrame()\n",
        "for compartimento in data['Tipo de Compartimento'].unique():\n",
        "    temp_data = data[data['Tipo de Compartimento'] == compartimento]\n",
        "    amostras = temp_data.iloc[:500]  # 150 primeiras amostras de cada compartimento\n",
        "    simplified_data = pd.concat([simplified_data, amostras], ignore_index=True)\n",
        "\n",
        "data = simplified_data.copy()\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "wNocavYWCy5v",
        "outputId": "47a5830f-c8ec-4144-edd0-028aa40eadbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "302                    Hidráulico\n",
              "303                   Diferencial\n",
              "304                       Redutor\n",
              "305                         motor\n",
              "306                   Diferencial\n",
              "                   ...           \n",
              "21422                       motor\n",
              "21423                 Transmissão\n",
              "21424                       motor\n",
              "21425    Sistema de Arrefecimento\n",
              "21426                       motor\n",
              "Name: Tipo de Compartimento, Length: 20945, dtype: object"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removendo a ocorrência dos valores 'Tanque de Combustível' e 'Sistema de Freio' da coluna 'Tipo de Compartimento'\n",
        "data = data[~data['Tipo de Compartimento'].isin(['Tanque Combustível Aeronave', 'Sistema de Freio'])].dropna()\n",
        "data.shape\n",
        "data['Tipo de Compartimento'].iloc[300:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in data.columns:\n",
        "    if data[column].dtype == np.float64:\n",
        "        data[column] = data[column].fillna(data[column].mean())\n",
        "    else:\n",
        "        data[column] = data[column].fillna(data[column].mode()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIRpRngNC1qh"
      },
      "source": [
        "# Convertendo modos de falha para reduzir a variabilidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "336KS-SYC42a",
        "outputId": "ce68978a-c971-4eb5-91f4-76e441ea772d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Modos de falha\n",
              "Sem perda de função parcial ou total evidente                                                           12992\n",
              "Perda das propriedades de maneira a afetar as suas características que permitam uma boa lubrificação     8253\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def group_failures(row):\n",
        "    if \"sem perda de função\" in row.lower():\n",
        "        return row\n",
        "\n",
        "    else:\n",
        "        return \"Perda das propriedades de maneira a afetar as suas características que permitam uma boa lubrificação\"\n",
        "\n",
        "data[\"Modos de falha\"] = data[\"Modos de falha\"].apply(group_failures)\n",
        "data[\"Modos de falha\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "PFffc3aSC51w",
        "outputId": "0d62e52e-13b4-49ee-d231-840d720f82bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        Sem perda de função parcial ou total evidente\n",
              "1        Sem perda de função parcial ou total evidente\n",
              "2    Perda das propriedades de maneira a afetar as ...\n",
              "3    Perda das propriedades de maneira a afetar as ...\n",
              "4        Sem perda de função parcial ou total evidente\n",
              "Name: Modos de falha, dtype: object"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Separar os modos de falha individuais\n",
        "modos_de_falha = []\n",
        "for row in data[\"Modos de falha\"].dropna():\n",
        "    modos_de_falha.extend(row.split(\". \"))\n",
        "\n",
        "# Contar as ocorrências de cada modo de falha\n",
        "contador = Counter(modos_de_falha)\n",
        "\n",
        "# Criar uma função para substituir os valores na coluna pelo mais frequente\n",
        "def modo_mais_frequente(texto):\n",
        "    falhas = texto.split(\". \")\n",
        "    return max(falhas, key=lambda x: contador[x])\n",
        "\n",
        "# Aplicar a função ao DataFrame\n",
        "data[\"Modos de falha\"] = data[\"Modos de falha\"].dropna().apply(modo_mais_frequente)\n",
        "\n",
        "data[\"Modos de falha\"].head()  # Exibir os primeiros resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePejHvjXC7Ov",
        "outputId": "7011f98b-0bc1-4414-b768-8559c7b83bd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Series([], dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "na_list = data.isna().sum()\n",
        "na_list = na_list[na_list > 0]\n",
        "print (na_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bQIMgCzC8JK",
        "outputId": "610cb335-1855-4d43-a024-241eded93d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Series([], dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "data['S70 µm'] = data['S70 µm'].fillna(data['S70 µm'].mean())\n",
        "na_list = data.isna().sum()\n",
        "na_list = na_list[na_list > 0]\n",
        "print (na_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqJHc2gGC9rH"
      },
      "source": [
        "# Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxPixCe1C-u4",
        "outputId": "bb76d312-4b2c-4d25-eebc-cc8251478e46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coluna Equipamento transformada com sucesso\n",
            "Coluna Tipo de Compartimento transformada com sucesso\n",
            "Coluna Tipo de Equipamento transformada com sucesso\n",
            "Coluna Óleo amostrado transformada com sucesso\n",
            "Coluna Tipo de amostra transformada com sucesso\n",
            "Coluna Alterações Físico-Químicas transformada com sucesso\n",
            "Coluna Avaliação do óleo transformada com sucesso\n",
            "Coluna Desgaste transformada com sucesso\n",
            "Coluna Avaliação do equipamento transformada com sucesso\n",
            "Coluna Contaminações transformada com sucesso\n",
            "Coluna Avaliação de contaminações transformada com sucesso\n",
            "Coluna Condição da amostra transformada com sucesso\n",
            "Coluna Modos de falha transformada com sucesso\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Usando label encoder para transformar as colunas categóricas em numéricas\n",
        "le = LabelEncoder()\n",
        "\n",
        "for column in data.select_dtypes(exclude=[np.number]).columns:\n",
        "  if column != 'Modos de falha':\n",
        "    data[column] = data[column].astype(str)\n",
        "    data[column] = le.fit_transform(data[column])\n",
        "    print(f'Coluna {column} transformada com sucesso')\n",
        "\n",
        "# Convert y_train to categorical using LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "data['Modos de falha'] = lb.fit_transform(data['Modos de falha'])\n",
        "print(f'Coluna Modos de falha transformada com sucesso')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dividindo a base em treino e teste\n",
        "X = data.drop('Modos de falha', axis=1)\n",
        "y = data['Modos de falha']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wbzSv1DAND"
      },
      "source": [
        "# SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3os_piQDBMP",
        "outputId": "5af36fb6-7fe3-488d-de94-6120de01e996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuição original: Counter({13: 8819, 11: 3961, 1: 3608, 2: 2111, 4: 1503, 0: 573, 7: 400, 12: 123, 9: 60, 10: 52, 8: 15, 3: 9, 5: 6, 6: 5})\n",
            "Nova distribuição: Counter({13: 8819, 1: 8819, 11: 8819, 0: 8819, 4: 8819, 2: 8819, 5: 8819, 7: 8819, 12: 8819, 10: 8819, 9: 8819, 3: 8819, 8: 8819, 6: 8819})\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "X = data.drop('Tipo de Compartimento', axis=1)\n",
        "y = data['Tipo de Compartimento']\n",
        "\n",
        "# Suponha que X são as features e y as classes\n",
        "print(f\"Distribuição original: {Counter(y)}\")\n",
        "\n",
        "# Aplicando SMOTE para gerar mais amostras da classe minoritária\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=3)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(f\"Nova distribuição: {Counter(y_resampled)}\")\n",
        "\n",
        "# Criando um novo DataFrame com os dados balanceados\n",
        "data_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "data_resampled['Tipo de Compartimento'] = y_resampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGfVk05fDDbh",
        "outputId": "3a35c368-75f4-40b2-a0b7-a8a53d74307a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{np.int64(0): np.int64(48327), np.int64(1): np.int64(38099)}\n"
          ]
        }
      ],
      "source": [
        "# Dividindo a base em treino e teste\n",
        "X = data_resampled.drop('Modos de falha', axis=1)\n",
        "y = data_resampled['Modos de falha']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sviZFPx4DFAg"
      },
      "source": [
        "# Treinamento dos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoglKvdbJCkH"
      },
      "source": [
        "## Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_iJQ9Va6QzyM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1215 candidates, totalling 6075 fits\n",
            "\n",
            "Melhores hiperparâmetros para MLP: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 64, 'hidden_layer_sizes': (64,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "Melhor acurácia na validação cruzada: 0.6812499999999999\n",
            "Acurácia no conjunto de teste (MLP): 0.6553398058252428\n",
            "     y_test  y_pred\n",
            "541       0       0\n",
            "664       1       0\n",
            "183       0       0\n",
            "287       0       0\n",
            "124       1       0\n",
            "..      ...     ...\n",
            "71        1       0\n",
            "469       0       0\n",
            "554       0       0\n",
            "627       0       0\n",
            "345       1       0\n",
            "\n",
            "[206 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definir o modelo MLP (Rede Neural)\n",
        "mlp_model = MLPClassifier(solver = 'adam', random_state=42)\n",
        "\n",
        "# Definir os hiperparâmetros para buscar\n",
        "param_grid_mlp = {\n",
        "    'hidden_layer_sizes': [(128,), (64,), (32,), (128, 64), (128, 64, 32)],  # Número de neurônios nas camadas ocultas\n",
        "    'activation': ['relu', 'tanh', 'logistic'],       # Função de ativação\n",
        "    'alpha': [0.0001, 0.001, 0.01],                  # Regularização (evita overfitting)\n",
        "    'learning_rate': ['constant', 'adaptive', 'invscaling'],       # Taxa de aprendizado\n",
        "    'max_iter': [1000, 2000, 5000],\n",
        "    'batch_size': [32, 64, 128],\n",
        "}\n",
        "\n",
        "# Criar o Grid Search com Validação Cruzada\n",
        "grid_search_mlp = GridSearchCV(mlp_model, param_grid_mlp, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "\n",
        "# Treinar o modelo\n",
        "grid_search_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Exibir os melhores hiperparâmetros encontrados\n",
        "print(\"\\nMelhores hiperparâmetros para MLP:\", grid_search_mlp.best_params_)\n",
        "print(\"Melhor acurácia na validação cruzada:\", grid_search_mlp.best_score_)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "best_mlp_model = grid_search_mlp.best_estimator_\n",
        "test_accuracy_mlp = best_mlp_model.score(X_test, y_test)\n",
        "print(\"Acurácia no conjunto de teste (MLP):\", test_accuracy_mlp)\n",
        "\n",
        "# Comparação visual\n",
        "y_pred = best_mlp_model.predict(X_test)\n",
        "comparison = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred})\n",
        "print(comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1215 candidates, totalling 6075 fits\n",
            "\n",
            "Melhores hiperparâmetros para MLP: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 64, 'hidden_layer_sizes': (64,), 'learning_rate': 'constant', 'max_iter': 1000}\n",
            "Melhor acurácia na validação cruzada: 0.6812499999999999\n",
            "Acurácia no conjunto de teste (MLP): 0.6553398058252428\n",
            "F1-score: 0.05333333333333334\n",
            "AUC-ROC: 0.5774722932651322\n",
            "MCC: -0.01770151413524594\n",
            "Elapsed time: 493.8112 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.neural_network import MLPClassifier \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "start_time_MLP = time.time()\n",
        "\n",
        "# Definir o modelo MLP (Rede Neural)\n",
        "mlp_model = MLPClassifier(solver = 'adam', random_state=42)\n",
        "\n",
        "# Definir os hiperparâmetros para buscar\n",
        "param_grid_mlp = {\n",
        "    'hidden_layer_sizes': [(128,), (64,), (32,), (128, 64), (128, 64, 32)],  # Número de neurônios nas camadas ocultas\n",
        "    'activation': ['relu', 'tanh', 'logistic'],       # Função de ativação\n",
        "    'alpha': [0.0001, 0.001, 0.01],                  # Regularização (evita overfitting)\n",
        "    'learning_rate': ['constant', 'adaptive', 'invscaling'],       # Taxa de aprendizado\n",
        "    'max_iter': [1000, 2000, 5000],\n",
        "    'batch_size': [32, 64, 128],\n",
        "}\n",
        "\n",
        "# Criar o Grid Search com Validação Cruzada\n",
        "grid_search_mlp = GridSearchCV(mlp_model, param_grid_mlp, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "\n",
        "# Treinar o modelo\n",
        "grid_search_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Exibir os melhores hiperparâmetros encontrados\n",
        "print(\"\\nMelhores hiperparâmetros para MLP:\", grid_search_mlp.best_params_)\n",
        "print(\"Melhor acurácia na validação cruzada:\", grid_search_mlp.best_score_)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "best_mlp_model = grid_search_mlp.best_estimator_\n",
        "y_pred = best_mlp_model.predict(X_test)\n",
        "y_prob = best_mlp_model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy_mlp = best_mlp_model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste (MLP):\", test_accuracy_mlp)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_MLP = time.time()\n",
        "elapsed_time_MLP = end_time_MLP - start_time_MLP\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_MLP:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino: 0.6833333333333333\n",
            "Acurácia no conjunto de teste (MLP): 0.6553398058252428\n",
            "F1-score: 0.05333333333333334\n",
            "AUC-ROC: 0.5774722932651322\n",
            "MCC: -0.01770151413524594\n",
            "Elapsed time: 0.1553 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "start_time_MLP = time.time()\n",
        "\n",
        "# Definir o modelo MLP (Rede Neural)\n",
        "mlp_model = MLPClassifier(solver='adam', activation='tanh', alpha=0.0001, batch_size=64, hidden_layer_sizes=(64,), learning_rate='constant', \n",
        "                          max_iter=1000, random_state=42)\n",
        "\n",
        "# Treinar o modelo\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "train_accuracy = mlp_model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino:\", train_accuracy)\n",
        "\n",
        "y_pred = mlp_model.predict(X_test)\n",
        "y_prob = mlp_model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy_mlp = mlp_model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste (MLP):\", test_accuracy_mlp)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_MLP = time.time()\n",
        "elapsed_time_MLP = end_time_MLP - start_time_MLP\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_MLP:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com a nova base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino: 0.7556109725685786\n",
            "Acurácia no conjunto de teste (MLP): 0.6878612716763006\n",
            "F1-score: 0.15625\n",
            "AUC-ROC: 0.5654934104789456\n",
            "MCC: 0.056150638436003236\n",
            "Elapsed time: 0.2856 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "start_time_MLP = time.time()\n",
        "\n",
        "# Definir o modelo MLP (Rede Neural)\n",
        "mlp_model = MLPClassifier(solver='adam', activation='tanh', alpha=0.0001, batch_size=64, hidden_layer_sizes=(64,), learning_rate='constant', \n",
        "                          max_iter=1000, random_state=42)\n",
        "\n",
        "# Treinar o modelo\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "train_accuracy = mlp_model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino:\", train_accuracy)\n",
        "\n",
        "y_pred = mlp_model.predict(X_test)\n",
        "y_prob = mlp_model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy_mlp = mlp_model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste (MLP):\", test_accuracy_mlp)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_MLP = time.time()\n",
        "elapsed_time_MLP = end_time_MLP - start_time_MLP\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_MLP:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino: 0.6551500705806124\n",
            "Isso é dataset completo\n",
            "Acurácia no conjunto de teste (MLP): 0.6508639308855292\n",
            "F1-score: 0.5212143650499815\n",
            "AUC-ROC: 0.7074973277390552\n",
            "MCC: 0.27970187148252046\n",
            "Elapsed time: 19.6750 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "start_time_MLP = time.time()\n",
        "\n",
        "# Definir o modelo MLP (Rede Neural)\n",
        "mlp_model = MLPClassifier(solver='adam', activation='tanh', alpha=0.0001, batch_size=64, hidden_layer_sizes=(64,), learning_rate='constant', \n",
        "                          max_iter=1000, random_state=42)\n",
        "\n",
        "# Treinar o modelo\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "train_accuracy = mlp_model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino:\", train_accuracy)\n",
        "\n",
        "y_pred = mlp_model.predict(X_test)\n",
        "y_prob = mlp_model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy_mlp = mlp_model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Isso é dataset completo\")\n",
        "\n",
        "print(\"Acurácia no conjunto de teste (MLP):\", test_accuracy_mlp)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_MLP = time.time()\n",
        "elapsed_time_MLP = end_time_MLP - start_time_MLP\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_MLP:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruQhrNYhJPx4"
      },
      "source": [
        "## Floresta Randômica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWTAexbVJvPh",
        "outputId": "fd907121-ab9f-4ac6-a7ad-1be39878e3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Melhores hiperparâmetros: {'max_depth': 100, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Melhor acurácia: 0.9979166666666668\n",
            "Acurácia no conjunto de teste: 0.9902912621359223\n",
            "Elapsed time: 53.1194 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "start_time_RF = time.time()\n",
        "\n",
        "# Definir o modelo\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Definir os hiperparâmetros a serem testados\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 500, 1000],  # Número de árvores\n",
        "    'max_depth': [None, 10, 20, 50, 100],    # Profundidade máxima da árvore\n",
        "    'min_samples_split': [2, 5, 10] # Mínimo de amostras para dividir um nó\n",
        "}\n",
        "\n",
        "# Criar o Grid Search com validação cruzada\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Treinar o modelo com todas as combinações\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mostrar os melhores hiperparâmetros encontrados\n",
        "print(\"\\nMelhores hiperparâmetros:\", grid_search.best_params_)\n",
        "print(\"Melhor acurácia:\", grid_search.best_score_)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "best_model = grid_search.best_estimator_\n",
        "test_accuracy = best_model.score(X_test, y_test)\n",
        "print(\"Acurácia no conjunto de teste:\", test_accuracy)\n",
        "\n",
        "end_time_RF = time.time()\n",
        "elapsed_time_RF = end_time_RF - start_time_RF\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_RF:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Melhores hiperparâmetros: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Melhor acurácia: 1.0\n",
            "Acurácia no conjunto de teste: 0.9854368932038835\n",
            "F1-score: 0.9784172661870504\n",
            "AUC-ROC: 0.9997868712702473\n",
            "MCC: 0.9679493288626012\n",
            "Elapsed time: 58.6498 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "start_time_RF = time.time()\n",
        "\n",
        "# Definir o modelo\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Definir os hiperparâmetros a serem testados\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 500, 1000],  # Número de árvores\n",
        "    'max_depth': [None, 10, 20, 50, 100],    # Profundidade máxima da árvore\n",
        "    'min_samples_split': [2, 5, 10] # Mínimo de amostras para dividir um nó\n",
        "}\n",
        "\n",
        "# Criar o Grid Search com validação cruzada\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Treinar o modelo com todas as combinações\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mostrar os melhores hiperparâmetros encontrados\n",
        "print(\"\\nMelhores hiperparâmetros:\", grid_search.best_params_)\n",
        "print(\"Melhor acurácia:\", grid_search.best_score_)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy = best_model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste:\", test_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_RF = time.time()\n",
        "elapsed_time_RF = end_time_RF - start_time_RF\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_RF:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino: 1.0\n",
            "Acurácia no conjunto de teste: 0.9902912621359223\n",
            "F1-score: 0.9855072463768116\n",
            "AUC-ROC: 0.999467178175618\n",
            "MCC: 0.9784425872172221\n",
            "Elapsed time: 0.2532 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "start_time_RF = time.time()\n",
        "\n",
        "# Definir o modelo\n",
        "model = RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "train_accuracy = model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino:\", train_accuracy)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy = model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste:\", test_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_RF = time.time()\n",
        "elapsed_time_RF = end_time_RF - start_time_RF\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_RF:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino: 0.9850374064837906\n",
            "Acurácia no conjunto de teste: 0.7341040462427746\n",
            "F1-score: 0.25806451612903225\n",
            "AUC-ROC: 0.7192221150755383\n",
            "MCC: 0.2471615909053938\n",
            "Elapsed time: 0.2111 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "start_time_RF = time.time()\n",
        "\n",
        "# Definir o modelo\n",
        "model = RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "train_accuracy = model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino:\", train_accuracy)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy = model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste:\", test_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_RF = time.time()\n",
        "elapsed_time_RF = end_time_RF - start_time_RF\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_RF:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino: 0.7990998079281698\n",
            "Isso é com dataset completo\n",
            "Acurácia no conjunto de teste: 0.7676835853131749\n",
            "F1-score: 0.6752707649345259\n",
            "AUC-ROC: 0.9061020797175667\n",
            "MCC: 0.5438171400637811\n",
            "Elapsed time: 15.9608 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "start_time_RF = time.time()\n",
        "\n",
        "# Definir o modelo\n",
        "model = RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "train_accuracy = model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino:\", train_accuracy)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy = model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Isso é com dataset completo\")\n",
        "\n",
        "print(\"Acurácia no conjunto de teste:\", test_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_RF = time.time()\n",
        "elapsed_time_RF = end_time_RF - start_time_RF\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_RF:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Melhores hiperparâmetros: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 500}\n",
            "Melhor acurácia: 0.7428571428571429\n",
            "Acurácia no conjunto de teste: 0.773015873015873\n",
            "F1-score: 0.8098404255319149\n",
            "AUC-ROC: 0.8409977445950018\n",
            "MCC: 0.5544575951529928\n",
            "Elapsed time: 186.5900 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "start_time_RF = time.time()\n",
        "\n",
        "# Definir o modelo\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Definir os hiperparâmetros a serem testados\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 500, 1000],  # Número de árvores\n",
        "    'max_depth': [None, 10, 20, 50, 100],    # Profundidade máxima da árvore\n",
        "    'min_samples_split': [2, 5, 10, 20] # Mínimo de amostras para dividir um nó\n",
        "}\n",
        "\n",
        "# Criar o Grid Search com validação cruzada\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Treinar o modelo com todas as combinações\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mostrar os melhores hiperparâmetros encontrados\n",
        "print(\"\\nMelhores hiperparâmetros:\", grid_search.best_params_)\n",
        "print(\"Melhor acurácia:\", grid_search.best_score_)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy = best_model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste:\", test_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_RF = time.time()\n",
        "elapsed_time_RF = end_time_RF - start_time_RF\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_RF:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Melhores hiperparâmetros: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 500}\n",
            "Melhor acurácia: 0.776734693877551\n",
            "Acurácia no conjunto de teste: 0.7695238095238095\n",
            "F1-score: 0.8071713147410359\n",
            "AUC-ROC: 0.8628399543578115\n",
            "MCC: 0.5610346028313454\n",
            "Elapsed time: 298.2967 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "start_time_RF = time.time()\n",
        "\n",
        "# Definir o modelo\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Definir os hiperparâmetros a serem testados\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 500, 1000],  # Número de árvores\n",
        "    'max_depth': [None, 10, 20, 50, 100],    # Profundidade máxima da árvore\n",
        "    'min_samples_split': [2, 5, 10, 20] # Mínimo de amostras para dividir um nó\n",
        "}\n",
        "\n",
        "# Criar o Grid Search com validação cruzada\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Treinar o modelo com todas as combinações\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mostrar os melhores hiperparâmetros encontrados\n",
        "print(\"\\nMelhores hiperparâmetros:\", grid_search.best_params_)\n",
        "print(\"Melhor acurácia:\", grid_search.best_score_)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy = best_model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste:\", test_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_RF = time.time()\n",
        "elapsed_time_RF = end_time_RF - start_time_RF\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_RF:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino: 0.990326984935089\n",
            "Isso é com dataset completo\n",
            "Acurácia no conjunto de teste: 0.8834233261339093\n",
            "F1-score: 0.8632419078989042\n",
            "AUC-ROC: 0.966484261467646\n",
            "MCC: 0.763224009941382\n",
            "Elapsed time: 133.5082 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "start_time_RF = time.time()\n",
        "\n",
        "# Definir o modelo\n",
        "model = RandomForestClassifier(max_depth=20, min_samples_split=5, n_estimators=500, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "train_accuracy = model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino:\", train_accuracy)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy = model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Isso é com dataset completo\")\n",
        "\n",
        "print(\"Acurácia no conjunto de teste:\", test_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_RF = time.time()\n",
        "elapsed_time_RF = end_time_RF - start_time_RF\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_RF:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino: 1.0\n",
            "Isso é com dataset completo\n",
            "Acurácia no conjunto de teste: 0.8990010799136069\n",
            "F1-score: 0.88545270828868\n",
            "AUC-ROC: 0.9720745449030677\n",
            "MCC: 0.7951362142617905\n",
            "Elapsed time: 61.9265 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "start_time_RF = time.time()\n",
        "\n",
        "# Definir o modelo\n",
        "model = RandomForestClassifier(max_depth=50, min_samples_split=5, n_estimators=200, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "train_accuracy = model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino:\", train_accuracy)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy = model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Isso é com dataset completo\")\n",
        "\n",
        "print(\"Acurácia no conjunto de teste:\", test_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_RF = time.time()\n",
        "elapsed_time_RF = end_time_RF - start_time_RF\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_RF:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOygx9NQJ1_M"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nww9yHi8J07I",
        "outputId": "a1c3ff35-1f77-4165-a175-066ffe244696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de teste (SVM): 0.7572815533980582\n",
            "F1-score: 0.5833333333333334\n",
            "AUC-ROC: 0.816069906223359\n",
            "MCC: 0.4238216326851869\n",
            "Elapsed time: 929.0432 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "start_time_SVM = time.time()\n",
        "\n",
        "# Definir o modelo SVM\n",
        "svm_model = SVC(C=0.1, kernel='linear', random_state=42, probability=True)\n",
        "\n",
        "# Treinar o modelo\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_pred = svm_model.predict(X_test)\n",
        "y_prob = svm_model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy_svm = svm_model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste (SVM):\", test_accuracy_svm)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_SVM = time.time()\n",
        "elapsed_time_SVM = end_time_SVM - start_time_SVM\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_SVM:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino (SVM): 0.775\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = svm_model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino (SVM):\", train_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de teste (SVM): 0.6936416184971098\n",
            "Acurácia no conjunto de treino (SVM): 0.7531172069825436\n",
            "F1-score: 0.18461538461538463\n",
            "AUC-ROC: 0.5675024108003857\n",
            "MCC: 0.08705975222792155\n",
            "Elapsed time: 1341.6386 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "start_time_SVM = time.time()\n",
        "\n",
        "# Definir o modelo SVM\n",
        "svm_model = SVC(C=0.1, kernel='linear', random_state=42, probability=True)\n",
        "\n",
        "# Treinar o modelo\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_pred = svm_model.predict(X_test)\n",
        "y_prob = svm_model.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "test_accuracy_svm = svm_model.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste (SVM):\", test_accuracy_svm)\n",
        "train_accuracy = svm_model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino (SVM):\", train_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)\n",
        "\n",
        "end_time_SVM = time.time()\n",
        "elapsed_time_SVM = end_time_SVM - start_time_SVM\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time_SVM:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de teste (ensemble): 0.7167630057803468\n",
            "Acurácia no conjunto de treino (ensemble): 0.7880299251870324\n",
            "F1-score: 0.14035087719298245\n",
            "AUC-ROC: 0.7192221150755383\n",
            "MCC: 0.15459250714356337\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', model),\n",
        "        ('ann', mlp_model),\n",
        "        ('svc', svm_model)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "ensemble.fit(X_train, y_train)\n",
        "ensemble.predict(X_test)\n",
        "\n",
        "#printando os resultados\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "test_accuracy_svm = ensemble.score(X_test, y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Acurácia no conjunto de teste (ensemble):\", test_accuracy_svm)\n",
        "train_accuracy = ensemble.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino (ensemble):\", train_accuracy)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"MCC:\", mcc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 19683 candidates, totalling 98415 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:04:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Melhores hiperparâmetros encontrados:\n",
            "{'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 500, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 1}\n",
            "\n",
            "Avaliação no conjunto de teste:\n",
            "Acurácia (Teste): 0.6936416184971098\n",
            "F1-score: 0.3116883116883117\n",
            "AUC-ROC: 0.7446158791385407\n",
            "MCC: 0.15379808171255632\n",
            "\n",
            "Tempo total de execução: 4034.72 segundos\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Classificador base\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Grade de hiperparâmetros expandida\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4],                # Reduz profundidade da árvore\n",
        "    'learning_rate': [0.01, 0.03, 0.05],   # Menores taxas de aprendizado\n",
        "    'n_estimators': [100, 300, 500],       # Mais árvores para compensar learning_rate menor\n",
        "    'subsample': [0.6, 0.8, 1],            # Amostragem de dados\n",
        "    'colsample_bytree': [0.6, 0.8, 1],     # Amostragem de features\n",
        "    'gamma': [0, 1, 5],                    # Mínimo ganho necessário para fazer split (penaliza splits)\n",
        "    'reg_alpha': [0, 1, 10],               # Regularização L1 (sparsidade)\n",
        "    'reg_lambda': [1, 5, 10],              # Regularização L2 (complexidade do modelo)\n",
        "    'min_child_weight': [1, 3, 5]          # Número mínimo de instâncias em uma folha\n",
        "}\n",
        "\n",
        "# Grid Search com F1-score como métrica principal\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinar grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Modelo final\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Avaliação\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nMelhores hiperparâmetros encontrados:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "print(\"\\nAvaliação no conjunto de teste:\")\n",
        "print(\"Acurácia (Teste):\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred))\n",
        "print(\"AUC-ROC:\", roc_auc_score(y_test, y_prob))\n",
        "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nTempo total de execução: {end_time - start_time:.2f} segundos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de treino (SVM): 1.0\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = best_model.score(X_train, y_train)\n",
        "print(\"Acurácia no conjunto de treino (SVM):\", train_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Melhores hiperparâmetros encontrados:\n",
            "{'C': 0.01, 'l1_ratio': 0.0, 'penalty': 'l2'}\n",
            "\n",
            "Avaliação no conjunto de teste:\n",
            "Acurácia (Teste): 0.6994219653179191\n",
            "F1-score: 0.07142857142857142\n",
            "AUC-ROC: 0.5388942462230795\n",
            "MCC: 0.0398049191287005\n",
            "\n",
            "Tempo total de execução: 54.36 segundos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, roc_auc_score, matthews_corrcoef, accuracy_score, make_scorer\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Modelo base\n",
        "logreg = LogisticRegression(solver='saga', max_iter=5000, random_state=42)\n",
        "\n",
        "# Grade de hiperparâmetros com foco em regularização\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],     # Tipos de penalização\n",
        "    'C': [0.01, 0.1, 1, 10],                   # Força da regularização inversa (valores menores = mais regularização)\n",
        "    'l1_ratio': [0.0, 0.5, 1.0]                # Usado só com elasticnet (entre L1 e L2)\n",
        "}\n",
        "\n",
        "# Grid search com F1-score como métrica principal\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=logreg,\n",
        "    param_grid=param_grid,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinando o modelo\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Melhor modelo encontrado\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nMelhores hiperparâmetros encontrados:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "print(\"\\nAvaliação no conjunto de teste:\")\n",
        "print(\"Acurácia (Teste):\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred))\n",
        "print(\"AUC-ROC:\", roc_auc_score(y_test, y_prob))\n",
        "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nTempo total de execução: {end_time - start_time:.2f} segundos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
